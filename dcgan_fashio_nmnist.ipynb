{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "\n",
    "CODING_SIZE = 100\n",
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = 64\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "                transforms.Resize(IMAGE_SIZE),\n",
    "                transforms.ToTensor(),\n",
    "                ])\n",
    "\n",
    "dataset = datasets.FashionMNIST(\n",
    "              './',\n",
    "              train=True,\n",
    "              download=True,\n",
    "              transform=transform\n",
    "              )\n",
    "dataloader = DataLoader(\n",
    "                 dataset,\n",
    "                 batch_size=BATCH_SIZE,\n",
    "                 shuffle=True\n",
    "                 )\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, coding_sz):\n",
    "        super(Generator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.ConvTranspose2d(coding_sz,\n",
    "                               1024, 4, 1, 0),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(1024,\n",
    "                               512, 4, 2, 1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(512,\n",
    "                               256, 4, 2, 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256,\n",
    "                               128, 4, 2, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128,\n",
    "                               1, 4, 2, 1),\n",
    "            nn.Tanh()\n",
    "            )\n",
    "    def forward(self, input):\n",
    "        return self.net(input)\n",
    "        \n",
    "netG = Generator(CODING_SIZE).to(device)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "        nn.Conv2d(1, 128, 4, 2, 1),\n",
    "        nn.LeakyReLU(0.2),\n",
    "        nn.Conv2d(128, 256, 4, 2, 1),\n",
    "        nn.BatchNorm2d(256),\n",
    "        nn.LeakyReLU(0.2),\n",
    "        nn.Conv2d(256, 512, 4, 2, 1),\n",
    "        nn.BatchNorm2d(512),\n",
    "        nn.LeakyReLU(0.2),\n",
    "        nn.Conv2d(512, 1024, 4, 2, 1),\n",
    "        nn.BatchNorm2d(1024),\n",
    "        nn.LeakyReLU(0.2),\n",
    "        nn.Conv2d(1024, 1, 4, 1, 0),\n",
    "        nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, input):\n",
    "        return self.net(input)\n",
    "        \n",
    "netD = Discriminator().to(device)\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "netG.apply(weights_init)\n",
    "netD.apply(weights_init)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "optimizerG = optim.Adam(netG.parameters(),\n",
    "                        lr=0.0002,\n",
    "                        betas=(0.5, 0.999))\n",
    "\n",
    "optimizerD = optim.Adam(netD.parameters(),\n",
    "                        lr=0.0001,\n",
    "                        betas=(0.5, 0.999))\n",
    "\n",
    "real_labels = torch.full((BATCH_SIZE,),\n",
    "                         1.,\n",
    "                         dtype=torch.float,\n",
    "                         device=device\n",
    "                         )\n",
    "\n",
    "fake_labels = torch.full((BATCH_SIZE,),\n",
    "                         0.,\n",
    "                         dtype=torch.float,\n",
    "                         device=device\n",
    "                         )\n",
    "\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "D_real = []\n",
    "D_fake = []\n",
    "\n",
    "z = torch.randn((\n",
    "    BATCH_SIZE, 100)).view(-1, 100, 1, 1).to(device)\n",
    "    \n",
    "test_out_images = []\n",
    "\n",
    "N_EPOCHS = 5\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    print(f'Epoch: {epoch}')\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        if (i%200==0):\n",
    "            print(f'batch: {i} of {len(dataloader)}')\n",
    "\n",
    "        # Train Discriminator with an all-real batch.\n",
    "        netD.zero_grad()\n",
    "        real_images = batch[0].to(device) *2. - 1.\n",
    "        output = netD(real_images).view(-1)\n",
    "        errD_real = criterion(output, real_labels)\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        # Train Discriminator with an all-fake batch.\n",
    "        noise = torch.randn((BATCH_SIZE, CODING_SIZE))\n",
    "        noise = noise.view(-1,100,1,1).to(device)\n",
    "        fake_images = netG(noise)\n",
    "        output = netD(fake_images).view(-1)\n",
    "        errD_fake = criterion(output, fake_labels)\n",
    "        D_G_z1 = output.mean().item()\n",
    "        errD = errD_real + errD_fake\n",
    "        errD.backward(retain_graph=True)\n",
    "        optimizerD.step()\n",
    "\n",
    "        # Train Generator to generate better fakes.\n",
    "        netG.zero_grad()\n",
    "        output = netD(fake_images).view(-1)\n",
    "        errG = criterion(output, real_labels)\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        optimizerG.step()\n",
    "\n",
    "        # Save losses for plotting later.\n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "        D_real.append(D_x)\n",
    "        D_fake.append(D_G_z2)\n",
    "\n",
    "        test_images = netG(z).to('cpu').detach()\n",
    "        test_out_images.append(test_images)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c3d4d9970fc5c09c50d9318a9c7fbf4d0159e4b28833276f5678ee22bded273"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
